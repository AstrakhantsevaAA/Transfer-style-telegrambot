{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer_style_telegram_bot.ipynb","provenance":[{"file_id":"1jxnSnj6v0Tog5okv2NCeqP0ReCknfk0k","timestamp":1582838645123}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"p_DfJodjPSP-","colab_type":"text"},"source":["# HOW TO RUN A TELEGRAM BOT IN COLAB"]},{"cell_type":"code","metadata":{"id":"ZQgn_FdDNsHs","colab_type":"code","outputId":"ab675ad6-ccdc-46c8-adaf-8e5de4e69187","executionInfo":{"status":"ok","timestamp":1583230748722,"user_tz":-180,"elapsed":1063,"user":{"displayName":"Alena Astrakhantseva","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDshuwEcGf5yda-9XhI3ualiEYf-GabSfAM-1Noag=s64","userId":"01214439313626185233"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile requirements.txt\n","\n","python-telegram-bot==12.4.2\n","tornado==4.5.3\n","ipykernel\n","scipy==1.1.0\n","torchvision\n","pillow==4.1.1\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Overwriting requirements.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eJi92LJ0FstP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fd90a1a0-70f1-41fc-d1aa-9672eb386cd2","executionInfo":{"status":"ok","timestamp":1583230769945,"user_tz":-180,"elapsed":19796,"user":{"displayName":"Alena Astrakhantseva","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDshuwEcGf5yda-9XhI3ualiEYf-GabSfAM-1Noag=s64","userId":"01214439313626185233"}}},"source":["!pip install -r requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting python-telegram-bot==12.4.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/5f/ab10cfacd6dba5deb7b7c3a78ddb23ae4404d6c6eb8b3c3e121668d4bf94/python_telegram_bot-12.4.2-py2.py3-none-any.whl (360kB)\n","\r\u001b[K     |█                               | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 5.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 81kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 92kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 102kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 112kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 133kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 143kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 153kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 163kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 174kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 184kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 194kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 204kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 215kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 225kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 235kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 245kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 256kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 266kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 276kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 286kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 296kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 307kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 317kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 327kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 337kB 7.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 348kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 358kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 368kB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: tornado==4.5.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (4.5.3)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.6.1)\n","Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 101kB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.5.0)\n","Collecting pillow==4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 33.9MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=4.4.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot==12.4.2->-r requirements.txt (line 2)) (4.4.1)\n","Collecting cryptography\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot==12.4.2->-r requirements.txt (line 2)) (0.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from python-telegram-bot==12.4.2->-r requirements.txt (line 2)) (2019.11.28)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 4)) (5.5.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 4)) (5.3.4)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->-r requirements.txt (line 4)) (4.3.3)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0->-r requirements.txt (line 5)) (1.17.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 6)) (1.12.0)\n","Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision->-r requirements.txt (line 6)) (1.4.0)\n","Collecting olefile\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 44.7MB/s \n","\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->python-telegram-bot==12.4.2->-r requirements.txt (line 2)) (1.14.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (0.8.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (1.0.18)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (45.1.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (0.7.5)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 4)) (2.6.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 4)) (17.0.0)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 4)) (4.6.2)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1.0->ipykernel->-r requirements.txt (line 4)) (0.2.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->python-telegram-bot==12.4.2->-r requirements.txt (line 2)) (2.19)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (0.1.8)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipykernel->-r requirements.txt (line 4)) (0.6.0)\n","Building wheels for collected packages: olefile\n","  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35417 sha256=2899d94ca55a03427707b7beb06fccee05b8f8ecb3406a80785b20ab96ccdea0\n","  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n","Successfully built olefile\n","\u001b[31mERROR: scikit-image 0.16.2 has requirement pillow>=4.3.0, but you'll have pillow 4.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","\u001b[31mERROR: python-telegram-bot 12.4.2 has requirement tornado>=5.1, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n","Installing collected packages: cryptography, python-telegram-bot, scipy, olefile, pillow\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Found existing installation: Pillow 6.2.2\n","    Uninstalling Pillow-6.2.2:\n","      Successfully uninstalled Pillow-6.2.2\n","Successfully installed cryptography-2.8 olefile-0.46 pillow-4.1.1 python-telegram-bot-12.4.2 scipy-1.1.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"gO7X0FDwxpvZ","colab_type":"code","colab":{}},"source":["from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from scipy import misc\n","import copy\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvWXUOA0wtVa","colab_type":"code","colab":{}},"source":["class ContentLoss(nn.Module):\n","        def __init__(self, target,):\n","            super().__init__()\n","            self.target = target.detach()\n","            self.loss = F.mse_loss(self.target, self.target)\n","\n","        def forward(self, input):\n","            self.loss = F.mse_loss(input, self.target)\n","            return input\n","\n","def gram_matrix(input):\n","        batch_size, h, w, f_map_num = input.size()  \n","        features = input.view(batch_size * h, w * f_map_num)  # resise F_XL into \\hat F_XL\n","\n","        G = torch.mm(features, features.t()) \n","\n","        # we 'normalize' the values of the gram matrix\n","        # by dividing by the number of element in each feature maps.\n","        return G.div(batch_size * h * w * f_map_num)\n","\n","class StyleLoss(nn.Module):\n","        def __init__(self, target_feature):\n","            super().__init__()\n","            self.target = gram_matrix(target_feature).detach()\n","            self.loss = F.mse_loss(self.target, self.target)\n","\n","        def forward(self, input):\n","            G = gram_matrix(input)\n","            self.loss = F.mse_loss(G, self.target)\n","            return input\n","\n","class Normalization(nn.Module):\n","        def __init__(self, mean, std):\n","            super().__init__()\n","            self.mean = torch.tensor(mean).view(-1, 1, 1)\n","            self.std = torch.tensor(std).view(-1, 1, 1)\n","\n","        def forward(self, img):\n","            return (img - self.mean) / self.std\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yDCmTiN8xRSg","colab_type":"code","colab":{}},"source":["def get_style_model_and_losses(cnn, normalization_mean, normalization_std,\n","                                   style_img, content_img,\n","                                   content_layers,\n","                                   style_layers):\n","        cnn = copy.deepcopy(cnn)\n","        normalization = Normalization(normalization_mean, normalization_std).to(device)\n","\n","        # just in order to have an iterable access to or list of content/syle\n","        # losses\n","        content_losses = []\n","        style_losses = []\n","\n","        # assuming that cnn is a nn.Sequential, so we make a new nn.Sequential\n","        # to put in modules that are supposed to be activated sequentially\n","        model = nn.Sequential(normalization)\n","\n","        i = 0  # increment every time we see a conv\n","        for layer in cnn.children():\n","            if isinstance(layer, nn.Conv2d):\n","                i += 1\n","                name = f'conv_{i}'\n","            elif isinstance(layer, nn.ReLU):\n","                name = f'relu_{i}'\n","                # The in-place version doesn't play very nicely with the ContentLoss\n","                # and StyleLoss we insert below. So we replace with out-of-place\n","                # ones here.\n","                layer = nn.ReLU(inplace=False)\n","            elif isinstance(layer, nn.MaxPool2d):\n","                name = f'pool_{i}'\n","            elif isinstance(layer, nn.BatchNorm2d):\n","                name = f'bn_{i}'\n","            else:\n","                raise RuntimeError(f'Unrecognized layer: {layer.__class__.__name__}')\n","\n","            model.add_module(name, layer)\n","\n","            if name in content_layers:\n","                target = model(content_img).detach()\n","                content_loss = ContentLoss(target)\n","                model.add_module(f\"content_loss_{i}\", content_loss)\n","                content_losses.append(content_loss)\n","\n","            if name in style_layers:\n","                target_feature = model(style_img).detach()\n","                style_loss = StyleLoss(target_feature)\n","                model.add_module(f\"style_loss_{i}\", style_loss)\n","                style_losses.append(style_loss)\n","\n","        # now we trim off the layers after the last content and style losses\n","        for i in range(len(model) - 1, -1, -1):\n","            if isinstance(model[i], ContentLoss) or isinstance(model[i], StyleLoss):\n","                break\n","\n","        model = model[:(i + 1)]\n","\n","        return model, style_losses, content_losses\n","\n","def get_input_optimizer(input_img):\n","        # this line to show that input is a parameter that requires a gradient\n","        optimizer = optim.LBFGS([input_img.requires_grad_()]) \n","        return optimizer\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5kE2U8EjVnr","colab_type":"code","colab":{}},"source":["class StyleTransferModel:\n","    def __init__(self):\n","        self.content_layers_default = ['conv_4']\n","        self.style_layers_default = ['conv_1','conv_2', 'conv_3', 'conv_4', 'conv_5']\n","        self.normalization_mean = torch.tensor([0.485, 0.456, 0.406]).to(device)\n","        self.normalization_std = torch.tensor([0.229, 0.224, 0.225]).to(device)\n","        self.cnn = models.vgg19(pretrained=True).features.to(device).eval()\n","        \n","    def transfer_style(self, content_img_stream, style_img_stream, \n","                       num_steps=500, style_weight=100000, content_weight=1):\n","        print(device)\n","        print('Building the style transfer model..')\n","        content_img = self.image_to_tensor(content_img_stream)\n","        style_img = self.image_to_tensor(style_img_stream)\n","        \n","        input_img = content_img.clone()\n","\n","        model, style_losses, content_losses = get_style_model_and_losses(\n","            self.cnn,\n","            self.normalization_mean,\n","            self.normalization_std, \n","            style_img, content_img,\n","            content_layers=self.content_layers_default,\n","            style_layers=self.style_layers_default\n","        )\n","        optimizer = get_input_optimizer(input_img)\n","        print('Optimizing..')\n","        run = [0]\n","        while run[0] <= num_steps:\n","\n","            def closure():\n","                # correct the values \n","                input_img.data.clamp_(0, 1)\n","\n","                optimizer.zero_grad()\n","\n","                model(input_img)\n","\n","                style_score = 0\n","                content_score = 0\n","\n","                for sl in style_losses:\n","                    style_score += sl.loss\n","                for cl in content_losses:\n","                    content_score += cl.loss\n","              \n","                style_score *= style_weight\n","                content_score *= content_weight\n","\n","                loss = style_score + content_score\n","                loss.backward()\n","\n","                run[0] += 1\n","                if run[0] % 50 == 0:\n","                    print(f\"run {run}:\")\n","                    print('Style Loss : {:4f} Content Loss: {:4f}'.format(\n","                        style_score.item(), content_score.item()))\n","                    print()\n","\n","                return style_score + content_score\n","\n","            optimizer.step(closure)\n","\n","        # a last correction...\n","        input_img.data.clamp_(0, 1)\n","        return self.tensor_to_image(input_img)\n","\n","    @staticmethod\n","    def image_to_tensor(img_stream, imsize=512):\n","        loader = transforms.Compose([\n","        transforms.Resize(imsize), \n","        transforms.CenterCrop(imsize),\n","        transforms.ToTensor()])  \n","\n","        image = Image.open(img_stream)\n","        image = loader(image).unsqueeze(0)\n","        return image.to(device, torch.float)\n","\n","    @staticmethod\n","    def tensor_to_image(tensor):\n","        unloader = transforms.ToPILImage()\n","        tensor = tensor.cpu().clone()   \n","        tensor = tensor.squeeze(0)     \n","        image = unloader(tensor)\n","        return misc.toimage(image)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbhD70R8jbcb","colab_type":"code","colab":{}},"source":["from io import BytesIO\n","from telegram.ext import Updater, MessageHandler, CommandHandler, Filters\n","import logging\n","\n","model = StyleTransferModel()\n","first_image_file = {}\n","\n","\n","def send_prediction_on_photo(bot, update):\n","\n","    chat_id = update.message.chat_id\n","    print(f\"Got image from {chat_id}\")\n","\n","    image_info = update.message.photo[-1]\n","    image_file = bot.get_file(image_info)\n","    \n","    if chat_id in first_image_file:\n","        # первая картинка, которая к нам пришла станет content image, а вторая style image\n","        content_image_stream = BytesIO()\n","        first_image_file[chat_id].download(out=content_image_stream)\n","        del first_image_file[chat_id]\n","\n","        style_image_stream = BytesIO()\n","        image_file.download(out=style_image_stream)\n","\n","        output = model.transfer_style(content_image_stream, style_image_stream, num_steps=200)\n","\n","        # теперь отправим назад фото\n","        output_stream = BytesIO()\n","        output.save(output_stream, format='PNG')\n","        output_stream.seek(0)\n","        bot.send_photo(chat_id, photo=output_stream)\n","        print(\"Sent Photo to user\")\n","    else:\n","        first_image_file[chat_id] = image_file\n","\n","def startCommand(bot, update):\n","    bot.send_message(chat_id=update.message.chat_id, text='Hey, just send me two photos!')\n","\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gm8aGFYgjiuK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"64b5d6ae-522d-426b-cd07-7edf68c6efc6"},"source":["token = '1021525121:AAFLQ3QaBengPrKBIiGTZdfzHRE1g4-O1tE'\n","logging.basicConfig(\n","        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n","        level=logging.INFO)\n","updater = Updater(token=token,  request_kwargs={'proxy_url': 'socks5h://163.172.152.192:1080'})\n","\n","updater.dispatcher.add_handler(CommandHandler('start', startCommand))\n","updater.dispatcher.add_handler(MessageHandler(Filters.photo, send_prediction_on_photo))\n","updater.start_polling(clean=True)\n","updater.idle()\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TelegramDeprecationWarning: Old Handler API is deprecated - see https://git.io/fxJuV for details\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["Got image from 82969866\n","Got image from 82969866\n","cuda\n","Building the style transfer model..\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["Optimizing..\n","run [50]:\n","Style Loss : 18.505602 Content Loss: 12.675617\n","\n","run [100]:\n","Style Loss : 5.982433 Content Loss: 11.752635\n","\n","run [150]:\n","Style Loss : 2.445985 Content Loss: 11.218088\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lBKxHYCIPm9V","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}